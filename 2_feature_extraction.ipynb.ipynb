{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T17:03:30.893524Z",
     "iopub.status.busy": "2024-12-07T17:03:30.893218Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "# Input and output directories\n",
    "audio_directory = \"/kaggle/input/infore/infore_16k_denoised\"\n",
    "output_directory = \"/kaggle/working/features\"\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"nguyenvulebinh/wav2vec2-base-vietnamese-250h\")\n",
    "model = Wav2Vec2Model.from_pretrained(\"nguyenvulebinh/wav2vec2-base-vietnamese-250h\")\n",
    "\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file_path):\n",
    "    speech, samplerate = sf.read(file_path)\n",
    "    return speech, samplerate\n",
    "\n",
    "# Helper function to extract features\n",
    "def extract_features(audio_file):\n",
    "    # Load audio\n",
    "    speech, samplerate = load_audio(audio_file)\n",
    "    duration = len(speech) / samplerate  # Calculate duration in seconds\n",
    "    \n",
    "    # Tokenize and preprocess\n",
    "    input_values = processor(speech, return_tensors=\"pt\", sampling_rate=16000).input_values.to(device)\n",
    "    \n",
    "    # Get features (output of Wav2Vec2 hidden states)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(input_values).last_hidden_state.squeeze(0)  # (time_steps, feature_dim)\n",
    "    \n",
    "    return embeddings.cpu().numpy(), duration  # Return features and duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000  # Number of audio files per batch\n",
    "audio_files = [os.path.join(audio_directory, f) for f in os.listdir(audio_directory) if f.endswith(\".wav\")]\n",
    "\n",
    "for batch_idx in range(0, len(audio_files), batch_size):\n",
    "    batch_files = audio_files[batch_idx:batch_idx + batch_size]\n",
    "    batch_features = {}\n",
    "\n",
    "    print(f\"Processing batch {batch_idx // batch_size + 1} with {len(batch_files)} files...\")\n",
    "\n",
    "    for idx, file in enumerate(batch_files):\n",
    "        try:\n",
    "            # Extract features and metadata\n",
    "            features, duration = extract_features(file)\n",
    "            batch_features[f\"file_{batch_idx * batch_size + idx + 1}\"] = {\n",
    "                \"features\": features,\n",
    "                \"path\": file,\n",
    "                \"duration\": duration,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "        \n",
    "        if (idx + 1) % 100 == 0:\n",
    "            print(f\"Processed {idx + 1} files in this batch...\")\n",
    "\n",
    "    # Save batch features\n",
    "    batch_output_path = os.path.join(output_directory, f\"features_batch_{batch_idx // batch_size + 1}.npz\")\n",
    "    np.savez_compressed(batch_output_path, **batch_features)\n",
    "    print(f\"Saved features for batch {batch_idx // batch_size + 1} to {batch_output_path}\")\n",
    "\n",
    "    del batch_features\n",
    "    gc.collect()\n",
    "\n",
    "print(\"Feature extraction complete!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6835843,
     "sourceId": 10983674,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
